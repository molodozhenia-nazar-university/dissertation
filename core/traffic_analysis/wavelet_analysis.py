import numpy
import pywt
import warnings

from scapy.all import rdpcap, TCP, UDP, ICMP, DNS

warnings.filterwarnings("ignore")

from core.traffic_analysis.traffic_analysis_information import set_packets
from core.traffic_analysis.traffic_analysis_information import set_packets_information
from core.traffic_analysis.traffic_analysis_information import build_packets_information


def wavelet_analysis(file_path, wavelet_type="db4", level=6, interval_sec=1):

    def extract_traffic_features(packets):

        timestamps = []
        sizes = []
        protocols = []

        for packet in packets:
            if hasattr(packet, "time"):
                timestamps.append(float(packet.time))
            if hasattr(packet, "len"):
                sizes.append(int(packet.len))

            # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –ø—Ä–æ—Ç–æ–∫–æ–ª—É
            proto = "OTHER"
            if packet.haslayer(TCP):
                proto = "TCP"
            elif packet.haslayer(UDP):
                proto = "UDP"
            elif packet.haslayer(ICMP):
                proto = "ICMP"
            elif packet.haslayer(DNS):
                proto = "DNS"
            protocols.append(proto)

        return timestamps, sizes, protocols

    def create_time_series(timestamps, sizes, interval_sec=1):
        """–°—Ç–≤–æ—Ä–∏—Ç–∏ —á–∞—Å–æ–≤—ñ —Ä—è–¥–∏ —Ç—Ä–∞—Ñ—ñ–∫—É"""
        if not timestamps:
            return numpy.array([]), numpy.array([])

        start_time = min(timestamps)
        end_time = max(timestamps)

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —á–∞—Å–æ–≤–∏—Ö —ñ–Ω—Ç–µ—Ä–≤–∞–ª—ñ–≤
        time_bins = numpy.arange(start_time, end_time + interval_sec, interval_sec)

        # –û–±'—î–º —Ç—Ä–∞—Ñ—ñ–∫—É –∑–∞ —ñ–Ω—Ç–µ—Ä–≤–∞–ª
        traffic_volume = numpy.zeros(len(time_bins) - 1)
        packet_count = numpy.zeros(len(time_bins) - 1)

        for i, (ts, size) in enumerate(zip(timestamps, sizes)):
            bin_idx = int((ts - start_time) // interval_sec)
            if 0 <= bin_idx < len(traffic_volume):
                traffic_volume[bin_idx] += size
                packet_count[bin_idx] += 1

        return traffic_volume, packet_count

    def detect_anomalies_wavelet(signal, wavelet="db4", level=6, threshold_std=3.0):
        """–í–∏—è–≤–ª–µ–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –≤–µ–π–≤–ª–µ—Ç-–∞–Ω–∞–ª—ñ–∑—É –î–æ–±–µ—à—ñ"""
        if len(signal) < 2**level:
            # –Ø–∫—â–æ —Å–∏–≥–Ω–∞–ª –∑–∞–∫–æ—Ä–æ—Ç–∫–∏–π, –∑–º–µ–Ω—à–∏—Ç–∏ —Ä—ñ–≤–µ–Ω—å
            level = max(1, int(numpy.log2(len(signal))) - 1)

        try:
            # –í–µ–π–≤–ª–µ—Ç-—Ä–æ–∑–∫–ª–∞–¥–∞–Ω–Ω—è
            coeffs = pywt.wavedec(signal, wavelet, level=level)

            anomalies = {
                "high_freq_anomalies": [],
                "low_freq_anomalies": [],
                "trend_breaks": [],
                "spikes": [],
            }

            # –ê–Ω–∞–ª—ñ–∑ –¥–µ—Ç–∞–ª—ñ–∑—É—é—á–∏—Ö –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤ (–≤–∏—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏)
            detail_coeffs = coeffs[1:]  # –í—Å—ñ –∫—Ä—ñ–º –∞–ø—Ä–æ–∫—Å–∏–º—É—é—á–∏—Ö

            for i, detail in enumerate(detail_coeffs):
                if len(detail) > 0:
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ —Ä—ñ–≤–Ω—è
                    std_level = numpy.std(detail)
                    mean_level = numpy.mean(detail)

                    # –í–∏—è–≤–ª–µ–Ω–Ω—è –≤–∏–∫–∏–¥—ñ–≤
                    outliers = numpy.where(
                        numpy.abs(detail - mean_level) > threshold_std * std_level
                    )[0]

                    for outlier_idx in outliers:
                        time_position = outlier_idx * (2 ** (i + 1))
                        magnitude = detail[outlier_idx]

                        anomalies["high_freq_anomalies"].append(
                            {
                                "time_position": time_position,
                                "magnitude": magnitude,
                                "level": i + 1,
                                "type": "HIGH_FREQ",
                            }
                        )

            # –ê–Ω–∞–ª—ñ–∑ –∞–ø—Ä–æ–∫—Å–∏–º—É—é—á–∏—Ö –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤ (–Ω–∏–∑—å–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏)
            approx_coeffs = coeffs[0]
            if len(approx_coeffs) > 10:
                std_approx = numpy.std(approx_coeffs)
                mean_approx = numpy.mean(approx_coeffs)

                # –í–∏—è–≤–ª–µ–Ω–Ω—è –∑–º—ñ–Ω —Ç—Ä–µ–Ω–¥—É
                trend_changes = numpy.where(
                    numpy.abs(approx_coeffs - mean_approx) > 2 * std_approx
                )[0]

                for change_idx in trend_changes:
                    anomalies["low_freq_anomalies"].append(
                        {
                            "time_position": change_idx * (2**level),
                            "magnitude": approx_coeffs[change_idx],
                            "type": "TREND_CHANGE",
                        }
                    )

            return anomalies, coeffs

        except Exception as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –≤–µ–π–≤–ª–µ—Ç-–∞–Ω–∞–ª—ñ–∑—É: {e}")
            return {}, []

    def analyze_protocol_anomalies(protocols, timestamps):
        """–ê–Ω–∞–ª—ñ–∑ –∞–Ω–æ–º–∞–ª—ñ–π —É —Ä–æ–∑–ø–æ–¥—ñ–ª—ñ –ø—Ä–æ—Ç–æ–∫–æ–ª—ñ–≤"""
        protocol_counts = {}
        protocol_timelines = {}

        for proto, ts in zip(protocols, timestamps):
            if proto not in protocol_counts:
                protocol_counts[proto] = 0
                protocol_timelines[proto] = []
            protocol_counts[proto] += 1
            protocol_timelines[proto].append(ts)

        anomalies = []

        # –ê–Ω–∞–ª—ñ–∑ —Ä–∞–ø—Ç–æ–≤–∏—Ö –∑–º—ñ–Ω —É –ø—Ä–æ—Ç–æ–∫–æ–ª–∞—Ö
        for proto, times in protocol_timelines.items():
            if len(times) > 10:
                time_diff = numpy.diff(sorted(times))
                if len(time_diff) > 0:
                    avg_interval = numpy.mean(time_diff)
                    std_interval = numpy.std(time_diff)

                    # –í–∏—è–≤–ª–µ–Ω–Ω—è —Å–ø–∞–ª–∞—Ö—ñ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
                    bursts = numpy.where(time_diff < avg_interval - 2 * std_interval)[0]
                    if len(bursts) > len(time_diff) * 0.3:  # –Ø–∫—â–æ –±—ñ–ª—å—à–µ 30% - –∞–Ω–æ–º–∞–ª—ñ—è
                        anomalies.append(
                            {
                                "type": "PROTOCOL_BURST",
                                "protocol": proto,
                                "burst_count": len(bursts),
                                "severity": (
                                    "HIGH"
                                    if len(bursts) > len(time_diff) * 0.5
                                    else "MEDIUM"
                                ),
                            }
                        )

        return anomalies, protocol_counts

    # –û–°–ù–û–í–ù–ê –õ–û–ì–Ü–ö–ê –§–£–ù–ö–¶–Ü–á
    try:
        print(f"üìñ –ß–∏—Ç–∞–Ω–Ω—è PCAP —Ñ–∞–π–ª—É: {file_path}")
        packets = rdpcap(file_path)

        if len(packets) == 0:
            return {"error": "–§–∞–π–ª –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –ø–∞–∫–µ—Ç—ñ–≤"}

        print(f"üì¶ –û–±—Ä–æ–±–∫–∞ {len(packets)} –ø–∞–∫–µ—Ç—ñ–≤...")

        set_packets(packets)

        set_packets_information(build_packets_information(packets))

        # –í–∏–¥—ñ–ª–µ–Ω–Ω—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ç—Ä–∞—Ñ—ñ–∫—É
        timestamps, sizes, protocols = extract_traffic_features(packets)

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤
        traffic_volume, packet_count = create_time_series(timestamps, sizes)

        if len(traffic_volume) == 0:
            return {"error": "–ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ —á–∞—Å–æ–≤—ñ —Ä—è–¥–∏"}

        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
        traffic_normalized = (traffic_volume - numpy.mean(traffic_volume)) / numpy.std(
            traffic_volume
        )
        packet_normalized = (packet_count - numpy.mean(packet_count)) / numpy.std(
            packet_count
        )

        # –í–ï–ô–í–õ–ï–¢-–ê–ù–ê–õ–Ü–ó
        print("üîç –í–∏–∫–æ–Ω–∞–Ω–Ω—è –≤–µ–π–≤–ª–µ—Ç-–∞–Ω–∞–ª—ñ–∑—É –î–æ–±–µ—à—ñ –î–ë4...")

        # –ê–Ω–∞–ª—ñ–∑ –æ–±'—î–º—É —Ç—Ä–∞—Ñ—ñ–∫—É
        volume_anomalies, volume_coeffs = detect_anomalies_wavelet(
            traffic_normalized, wavelet_type, level
        )

        # –ê–Ω–∞–ª—ñ–∑ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ø–∞–∫–µ—Ç—ñ–≤
        packet_anomalies, packet_coeffs = detect_anomalies_wavelet(
            packet_normalized, wavelet_type, level
        )

        # –ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª—ñ–≤
        protocol_anomalies, protocol_stats = analyze_protocol_anomalies(
            protocols, timestamps
        )

        # –§–û–†–ú–£–í–ê–ù–ù–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í
        results = {
            "summary": {
                "total_packets": len(packets),
                "analysis_duration": f"{len(traffic_volume)} —ñ–Ω—Ç–µ—Ä–≤–∞–ª—ñ–≤",
                "wavelet_type": wavelet_type,
                "wavelet_level": level,
            },
            "traffic_stats": {
                "total_volume": sum(sizes),
                "avg_packet_size": numpy.mean(sizes) if sizes else 0,
                "time_range": f"{min(timestamps) if timestamps else 0:.1f} - {max(timestamps) if timestamps else 0:.1f} —Å–µ–∫",
            },
            "protocol_distribution": protocol_stats,
            "detected_anomalies": {
                "volume_anomalies": len(
                    volume_anomalies.get("high_freq_anomalies", [])
                ),
                "packet_anomalies": len(
                    packet_anomalies.get("high_freq_anomalies", [])
                ),
                "protocol_anomalies": len(protocol_anomalies),
                "trend_changes": len(volume_anomalies.get("low_freq_anomalies", [])),
            },
            "detailed_findings": {
                "high_frequency_spikes": volume_anomalies.get(
                    "high_freq_anomalies", []
                ),
                "traffic_trend_changes": volume_anomalies.get("low_freq_anomalies", []),
                "protocol_bursts": protocol_anomalies,
            },
            "recommendations": [],
        }

        # –§–û–†–ú–£–í–ê–ù–ù–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–ô
        total_anomalies = (
            results["detected_anomalies"]["volume_anomalies"]
            + results["detected_anomalies"]["packet_anomalies"]
            + results["detected_anomalies"]["protocol_anomalies"]
        )

        if total_anomalies > 20:
            results["recommendations"].append(
                "üö® –í–ò–°–û–ö–ò–ô –†–Ü–í–ï–ù–¨ –ó–ê–ì–†–û–ó: –ú–æ–∂–ª–∏–≤–∞ DDoS –∞—Ç–∞–∫–∞ –∞–±–æ –º–∞—Å–æ–≤–∞–Ω–∞ –∞–Ω–æ–º–∞–ª—å–Ω–∞ –∞–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å"
            )
        elif total_anomalies > 10:
            results["recommendations"].append(
                "‚ö†Ô∏è –°–ï–†–ï–î–ù–Ü–ô –†–Ü–í–ï–ù–¨: –í–∏—è–≤–ª–µ–Ω–æ –ø–æ–º—ñ—Ä–Ω—É –∞–Ω–æ–º–∞–ª—å–Ω—É –∞–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å"
            )
        elif total_anomalies > 0:
            results["recommendations"].append("‚ÑπÔ∏è –ù–ò–ó–¨–ö–ò–ô –†–Ü–í–ï–ù–¨: –ù–µ–∑–Ω–∞—á–Ω—ñ –∞–Ω–æ–º–∞–ª—ñ—ó")
        else:
            results["recommendations"].append("‚úÖ –ù–û–†–ú–ê: –ê–Ω–æ–º–∞–ª—ñ–π –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ")

        # –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        if results["detected_anomalies"]["protocol_anomalies"] > 0:
            results["recommendations"].append(
                "üîç –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ø—ñ–¥–æ–∑—Ä—ñ–ª—É –ø—Ä–æ—Ç–æ–∫–æ–ª—å–Ω—É –∞–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å"
            )

        if results["detected_anomalies"]["trend_changes"] > 2:
            results["recommendations"].append("üìà –í–∏—è–≤–ª–µ–Ω—ñ —Ä—ñ–∑–∫—ñ –∑–º—ñ–Ω–∏ —Ç—Ä–µ–Ω–¥—É —Ç—Ä–∞—Ñ—ñ–∫—É")

        print("‚úÖ –í–µ–π–≤–ª–µ—Ç-–∞–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
        return results

    except Exception as e:
        return {"error": f"–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É: {str(e)}"}
